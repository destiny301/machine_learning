{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8fSrkS19rqK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OGFeW3hA3GtB",
    "outputId": "dc75faf9-61d9-4109-83a4-8878eed8e9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd ./drive/My\\ Drive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swQalLZe3gDJ"
   },
   "outputs": [],
   "source": [
    "folder = './aclImdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAq3Dkm33gHr"
   },
   "outputs": [],
   "source": [
    "xtr = []\n",
    "xte = []\n",
    "\n",
    "ytr = []\n",
    "yte = []\n",
    "for dir in os.listdir(folder):\n",
    "  if dir == 'test':\n",
    "    for filedir in os.listdir(folder+'/'+dir):\n",
    "      filefolder = folder+'/'+dir+'/'+filedir\n",
    "\n",
    "      if filedir == 'neg':\n",
    "        for file in os.listdir(filefolder):\n",
    "          filepath = os.path.join(filefolder, file)\n",
    "          xte.append(open(filepath, encoding='UTF-8').read().strip())\n",
    "          yte.append(0)\n",
    "      if filedir == 'pos':\n",
    "        for file in os.listdir(filefolder):\n",
    "          filepath = os.path.join(filefolder, file)\n",
    "          xte.append(open(filepath, encoding='UTF-8').read().strip())\n",
    "          yte.append(1)\n",
    "    # print('test')\n",
    "  if dir == 'train':\n",
    "    for filedir in os.listdir(folder+'/'+dir):\n",
    "      filefolder = folder+'/'+dir+'/'+filedir\n",
    "\n",
    "      if filedir == 'neg':\n",
    "        for file in os.listdir(filefolder):\n",
    "          filepath = os.path.join(filefolder, file)\n",
    "          xtr.append(open(filepath, encoding='UTF-8').read().strip())\n",
    "          ytr.append(0)\n",
    "      if filedir == 'pos':\n",
    "        for file in os.listdir(filefolder):\n",
    "          filepath = os.path.join(filefolder, file)\n",
    "          xtr.append(open(filepath, encoding='UTF-8').read().strip())\n",
    "          ytr.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "cCyDa4vF3gBT",
    "outputId": "cd972079-2942-47fe-f141-f565c8939268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n",
      "25000 25000\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies. 0\n",
      "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4. 0\n"
     ]
    }
   ],
   "source": [
    "print(len(xtr), len(xte))\n",
    "print(len(ytr), len(yte))\n",
    "print(xtr[1], ytr[1])\n",
    "print(xte[1], yte[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgsUppQTNGsP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(w):\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "4q_iiRgU3f6T",
    "outputId": "a07b49cc-5e15-4635-8b2c-013db9aed7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Am Curious Yellow is a risible and pretentious steaming pile . It doesn t matter what one s political views are because this film can hardly be taken seriously on any level . As for the claim that frontal male nudity is an automatic NC , that isn t true . I ve seen R rated films with male nudity . Granted , they only offer some fleeting views , but where are the R rated films with gaping vulvas and flapping labia ? Nowhere , because they don t exist . The same goes for those crappy cable shows schlongs swinging in the breeze but not a clitoris in sight . And those pretentious indie movies like The Brown Bunny , in which we re treated to the site of Vincent Gallo s throbbing johnson , but not a trace of pink visible on Chloe Sevigny . Before crying or implying double standard in matters of nudity , the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women there are no genitals on display when actresses appears nude , and the same cannot be said for a man . In fact , you generally won t see female genitals in an American film in anything short of porn or explicit erotica . This alleged double standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women s bodies .\n",
      "Worth the entertainment value of a rental , especially if you like action movies . This one features the usual car chases , fights with the great Van Damme kick style , shooting battles with the shell load shotgun , and even terrorist style bombs . All of this is entertaining and competently handled but there is nothing that really blows you away if you ve seen your share before . br br The plot is made interesting by the inclusion of a rabbit , which is clever but hardly profound . Many of the characters are heavily stereotyped the angry veterans , the terrified illegal aliens , the crooked cops , the indifferent feds , the bitchy tough lady station head , the crooked politician , the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the s . All passably acted but again nothing special . br br I thought the main villains were pretty well done and fairly well acted . By the end of the movie you certainly knew who the good guys were and weren t . There was an emotional lift as the really bad ones got their just deserts . Very simplistic , but then you weren t expecting Hamlet , right ? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene . br br Not bad . Not good . Passable .\n"
     ]
    }
   ],
   "source": [
    "xtrain = []\n",
    "xtest = []\n",
    "for s in xtr:\n",
    "  xtrain.append(preprocess(s))\n",
    "for s in xte:\n",
    "  xtest.append(preprocess(s))\n",
    "\n",
    "print(xtrain[1])\n",
    "print(xtest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNhaunMjV_05"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOlBOUm2WLn0"
   },
   "outputs": [],
   "source": [
    "train_tensor, inp_lang_tokenizer = tokenize(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UeAhb82BWZwA",
    "outputId": "0236d1ee-edc5-4ea4-e138-418b13e8e22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "test_tensor = inp_lang_tokenizer.texts_to_sequences(xtest)\n",
    "test_tensor = tf.keras.preprocessing.sequence.pad_sequences(test_tensor,\n",
    "                                                        padding='post')\n",
    "\n",
    "print(len(train_tensor), len(test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0QTuAYaMEYL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_label, test_label = to_categorical(ytr), to_categorical(yte)\n",
    "vocab_size = len(inp_lang_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "unis7hllYN1B",
    "outputId": "0bfa51d2-8fc1-4cee-e654-22609f8a3757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          4689792   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 4,801,346\n",
      "Trainable params: 4,801,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, 64),\n",
    "        layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(32)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6BJEd6pYN6V"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "dNalasX3ZVGp",
    "outputId": "a50ed73b-7b78-414f-d8f8-cacac13a6a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 58s 729ms/step - loss: 0.6695 - accuracy: 0.6238 - auc: 0.6277 - val_loss: 0.9813 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 57s 718ms/step - loss: 0.6582 - accuracy: 0.6250 - auc: 0.6474 - val_loss: 0.9967 - val_accuracy: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 57s 718ms/step - loss: 0.5719 - accuracy: 0.7138 - auc: 0.7872 - val_loss: 0.9690 - val_accuracy: 0.5238 - val_auc: 0.3705\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 57s 719ms/step - loss: 0.3740 - accuracy: 0.8564 - auc: 0.9176 - val_loss: 0.6103 - val_accuracy: 0.7608 - val_auc: 0.7499\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 57s 718ms/step - loss: 0.2406 - accuracy: 0.9168 - auc: 0.9622 - val_loss: 0.4561 - val_accuracy: 0.8332 - val_auc: 0.8690\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 57s 720ms/step - loss: 0.1833 - accuracy: 0.9427 - auc: 0.9756 - val_loss: 0.5872 - val_accuracy: 0.7866 - val_auc: 0.8233\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 57s 721ms/step - loss: 0.1352 - accuracy: 0.9610 - auc: 0.9845 - val_loss: 0.5358 - val_accuracy: 0.8130 - val_auc: 0.8630\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 57s 724ms/step - loss: 0.1078 - accuracy: 0.9702 - auc: 0.9890 - val_loss: 0.8293 - val_accuracy: 0.7462 - val_auc: 0.7803\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 57s 724ms/step - loss: 0.0787 - accuracy: 0.9814 - auc: 0.9925 - val_loss: 0.8556 - val_accuracy: 0.7484 - val_auc: 0.7955\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 57s 726ms/step - loss: 0.0591 - accuracy: 0.9868 - auc: 0.9946 - val_loss: 1.1301 - val_accuracy: 0.7060 - val_auc: 0.7291\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_tensor, train_label, epochs=10, batch_size=256, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IY6UXkCBFL8P",
    "outputId": "e3da660a-df9b-4aed-ffe8-34872c362715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 123s 157ms/step - loss: 0.6058 - accuracy: 0.8338 - auc: 0.9009\n",
      "test auc: 0.9008569717407227\n"
     ]
    }
   ],
   "source": [
    "loss, acc, auc = model.evaluate(test_tensor, test_label)\n",
    "print(\"test auc:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HO1-gAbekav"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ml_week04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
