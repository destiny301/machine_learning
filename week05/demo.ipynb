{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_week05.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP1y2TkZmXvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06862588-5219-4350-d9f8-cf945987fef1"
      },
      "source": [
        "cd ./drive/My\\ Drive/Colab\\ Notebooks/data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwJwIYv5mhP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget --quiet http://www.manythings.org/anki/deu-eng.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSvcv9mRm6Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip deu-eng.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS1051f2m-R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import io\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp8JVYg5w6rJ",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXJD_3KioSEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = './deu.txt'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUJGi726oXsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn')\n",
        "  \n",
        "def preprocess(s):\n",
        "  s = unicode_to_ascii(s.lower().strip())\n",
        "\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1\", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  \n",
        "  s = s.strip()\n",
        "\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek4EL_JLrDqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2b60e30-0099-4e70-b53c-ad7aa3d92410"
      },
      "source": [
        "en_s = u'May I borrow this book?'\n",
        "print(preprocess(en_s))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVsgwzmaqRB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess(w) for w in l.split('\\t')[:2]]  for l in lines[:num]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN-l4nG7sZl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "560d69b2-e748-48a7-f167-66729b843713"
      },
      "source": [
        "eng, deu = create_dataset(filepath, None)\n",
        "print(eng[-1])\n",
        "print(deu[-1]) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
            "<start> ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht , dass ein mensch nur gelegenheit hat , mit ein paar hundert anderen bekannt zu sein , von denen ihm nur ein dutzend oder weniger nahesteht , darunter hochstens ein oder zwei freunde , dann erahnt man eingedenk der millionen einwohner dieser welt leicht , dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B8XnXFDsme-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nucUcpMlt0IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num):\n",
        "  tar_lang, sour_lang = create_dataset(path, num)\n",
        "\n",
        "  tar_tensor, tar_tokenizer = tokenize(tar_lang)\n",
        "  sour_tensor, sour_tokenizer = tokenize(sour_lang)\n",
        "\n",
        "  return tar_tensor, sour_tensor, tar_tokenizer, sour_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDfcoVqLupNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 30000\n",
        "y_tensor, x_tensor, y_tokenizer, x_tokenizer = load_dataset(filepath, num)\n",
        "\n",
        "x_max_length, y_max_length = x_tensor.shape[1], y_tensor.shape[1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvvTkCu6vHmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63870d85-822d-49c3-b281-3cb55665a76f"
      },
      "source": [
        "print(x_max_length, y_max_length)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf4P9VFhvRCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4895c964-3fa1-4a84-d6a1-a4f8868ed735"
      },
      "source": [
        "xtr_tensor, xte_tensor, ytr_tensor, yte_tensor = train_test_split(x_tensor, y_tensor, test_size = 0.2)\n",
        "\n",
        "print(len(xtr_tensor), len(ytr_tensor), len(xte_tensor), len(yte_tensor))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft67ADekuYJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib9fMMpLuZH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3e496b54-2382-459c-b3dd-c904e9a47804"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(x_tokenizer, xtr_tensor[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(y_tokenizer, ytr_tensor[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "27 ----> ihr\n",
            "233 ----> braucht\n",
            "41 ----> einen\n",
            "566 ----> anwalt\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "7 ----> you\n",
            "55 ----> need\n",
            "11 ----> a\n",
            "406 ----> lawyer\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8X39ErJv0kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create tf.dataset\n",
        "BUFFER_SIZE = len(xtr_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(xtr_tensor)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(x_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(y_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((xtr_tensor, ytr_tensor)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdPHu2dQwz9A",
        "colab_type": "text"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUH2XyxKwzEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwEPE_hopwCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "60dbfd0f-b441-45e7-b105-80c2d41cc853"
      },
      "source": [
        "# encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# # sample input\n",
        "# example_input_batch, example_target_batch = next(iter(dataset))\n",
        "\n",
        "# sample_hidden = encoder.initialize_hidden_state()\n",
        "# sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "# print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 14, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqi1dny0wskN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1) # (batch_size, hidden size)-->(batch_size, 1, hidden size)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis)+self.W2(values)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3gcBXSGqCKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "27b38249-dae5-4089-d813-b4986055497b"
      },
      "source": [
        "# attention_layer = BahdanauAttention(10)\n",
        "# attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "# print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "# print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxW_LL2l2oEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences = True,\n",
        "                                   return_state = True,\n",
        "                                   recurrent_initializer = 'glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "  \n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2])) # (batch_size * 1, hidden_size)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSbGGA-qEOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "579e8f08-d03e-4f59-85e8-b7ac772c60fd"
      },
      "source": [
        "# decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "#                                       sample_hidden, sample_output)\n",
        "\n",
        "# print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4552)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6DNGKGK56bS",
        "colab_type": "text"
      },
      "source": [
        "## optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lYhwsNo2u4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBkFHB136udy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp0-aqyU6wbw",
        "colab_type": "text"
      },
      "source": [
        "# Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW4n_6PW6vZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def train_step(inp, targ, enc_hidden, acc_object):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([y_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      pred = np.argmax(predictions, axis = 1)\n",
        "      acc_object.update_state(targ[:, t], pred)\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss, acc_object"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5u6u0AY64fV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "676c4312-7c55-4484-b70a-cf26a8652682"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss, acc = train_step(inp, targ, enc_hidden, acc)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f} Acc {:.4f}'.format(epoch + 1, batch, batch_loss.numpy(), acc.result().numpy()))\n",
        "\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f} Acc {:.4f}\\n'.format(epoch + 1, total_loss / steps_per_epoch, acc.result().numpy()))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.8565 Acc0.0000\n",
            "Epoch 1 Batch 100 Loss 2.1057 Acc0.1990\n",
            "Epoch 1 Batch 200 Loss 1.7547 Acc0.2360\n",
            "Epoch 1 Batch 300 Loss 1.6475 Acc0.2630\n",
            "Epoch 1 Loss 1.9389 Acc 0.2779\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4394 Acc0.3420\n",
            "Epoch 2 Batch 100 Loss 1.3540 Acc0.3576\n",
            "Epoch 2 Batch 200 Loss 1.1527 Acc0.3640\n",
            "Epoch 2 Batch 300 Loss 1.2860 Acc0.3716\n",
            "Epoch 2 Loss 1.2727 Acc 0.3764\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0256 Acc0.4132\n",
            "Epoch 3 Batch 100 Loss 0.9657 Acc0.4154\n",
            "Epoch 3 Batch 200 Loss 0.8932 Acc0.4204\n",
            "Epoch 3 Batch 300 Loss 0.8587 Acc0.4263\n",
            "Epoch 3 Loss 0.9078 Acc 0.4300\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6119 Acc0.4583\n",
            "Epoch 4 Batch 100 Loss 0.5279 Acc0.4710\n",
            "Epoch 4 Batch 200 Loss 0.6502 Acc0.4723\n",
            "Epoch 4 Batch 300 Loss 0.6181 Acc0.4753\n",
            "Epoch 4 Loss 0.6148 Acc 0.4777\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4283 Acc0.5278\n",
            "Epoch 5 Batch 100 Loss 0.4651 Acc0.5178\n",
            "Epoch 5 Batch 200 Loss 0.4956 Acc0.5157\n",
            "Epoch 5 Batch 300 Loss 0.4116 Acc0.5154\n",
            "Epoch 5 Loss 0.4085 Acc 0.5164\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2507 Acc0.5486\n",
            "Epoch 6 Batch 100 Loss 0.2340 Acc0.5544\n",
            "Epoch 6 Batch 200 Loss 0.2717 Acc0.5497\n",
            "Epoch 6 Batch 300 Loss 0.2874 Acc0.5481\n",
            "Epoch 6 Loss 0.2695 Acc 0.5481\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1722 Acc0.5938\n",
            "Epoch 7 Batch 100 Loss 0.1766 Acc0.5744\n",
            "Epoch 7 Batch 200 Loss 0.2126 Acc0.5729\n",
            "Epoch 7 Batch 300 Loss 0.2088 Acc0.5716\n",
            "Epoch 7 Loss 0.1850 Acc 0.5703\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1259 Acc0.5885\n",
            "Epoch 8 Batch 100 Loss 0.1143 Acc0.5895\n",
            "Epoch 8 Batch 200 Loss 0.1394 Acc0.5888\n",
            "Epoch 8 Batch 300 Loss 0.1580 Acc0.5866\n",
            "Epoch 8 Loss 0.1321 Acc 0.5858\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0588 Acc0.5868\n",
            "Epoch 9 Batch 100 Loss 0.0876 Acc0.5990\n",
            "Epoch 9 Batch 200 Loss 0.1104 Acc0.5977\n",
            "Epoch 9 Batch 300 Loss 0.1366 Acc0.5966\n",
            "Epoch 9 Loss 0.1033 Acc 0.5953\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0794 Acc0.5920\n",
            "Epoch 10 Batch 100 Loss 0.0834 Acc0.6018\n",
            "Epoch 10 Batch 200 Loss 0.0789 Acc0.6014\n",
            "Epoch 10 Batch 300 Loss 0.1144 Acc0.6005\n",
            "Epoch 10 Loss 0.0882 Acc 0.6001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuenLjeypazv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  # sentence = preprocess(sentence)\n",
        "\n",
        "  inputs = [x_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=x_max_length, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([y_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(y_max_length):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += y_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if y_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuDrceTHL02Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def translate(sentence):\n",
        "  result, sentence = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  score = sentence_bleu(sentence, result)\n",
        "  print(\"BLEU score:\", score)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEBlyy8BL7z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d7762d8-6d96-42e8-9b31-51316a0a2ae6"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f653ce5fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEPevGEfL8n5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6b74ba1a-a8b9-4a0c-c401-3858bc1d8db6"
      },
      "source": [
        "translate(deu[1000])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> setz dich dorthin . <end>\n",
            "Predicted translation: sit there . <end> \n",
            "BLEU score: 0.9036020036098448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu4u2vtqPztD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4279bd71-81d4-427d-fb1a-c3eb2eec513f"
      },
      "source": [
        "translate(deu[2000])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> bist du in form ? <end>\n",
            "Predicted translation: are you fit ? <end> \n",
            "BLEU score: 0.9146912192286945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzpLBvtWQmZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3d49533c-dc29-4ac6-a64d-941e3debcd83"
      },
      "source": [
        "translate(deu[12000])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ich wunsche dir gluck . <end>\n",
            "Predicted translation: i want your step . <end> \n",
            "BLEU score: 0.8650615454144222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S9S3uJKQqrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}